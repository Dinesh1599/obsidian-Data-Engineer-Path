![[Pasted image 20260122225447.png]]

Spark works on a Cluster of Computers.

Driver program: Responsible for running code and scheduling tasks on executors.

Executor Node: A JVM that perform the actual calculation and processing

Cluster Manager: The Cluster Manager is responsible to manage the resources(Clusters).

Spark Con